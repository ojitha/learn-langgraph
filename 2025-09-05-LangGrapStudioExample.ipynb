{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b887f0",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b9d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv .env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58fc06e",
   "metadata": {},
   "source": [
    "Import the follwoing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c979de66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "from agents.example1.Example1Agent import graph\n",
    "from typing import TypedDict, Literal, Annotated, Sequence\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "import operator\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c21c79b",
   "metadata": {},
   "source": [
    "Here the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a964b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from typing import TypedDict, Literal, Annotated, Sequence\n",
       "from langgraph.graph import StateGraph, START, END\n",
       "from langchain_openai import ChatOpenAI\n",
       "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
       "import operator\n",
       "\n",
       "class AgentState(TypedDict):\n",
       "    messages: Annotated[Sequence[HumanMessage | AIMessage | SystemMessage], operator.add]\n",
       "\n",
       "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
       "\n",
       "def get_weather(location: str) -> str:\n",
       "    \"\"\"Get the current weather for a location.\"\"\"\n",
       "    weather_data = {\n",
       "        \"london\": \"Cloudy with light rain, 15Â°C\",\n",
       "        \"paris\": \"Sunny and warm, 22Â°C\", \n",
       "        \"new york\": \"Partly cloudy, 18Â°C\",\n",
       "        \"tokyo\": \"Clear skies, 25Â°C\"\n",
       "    }\n",
       "    location_lower = location.lower()\n",
       "    if location_lower in weather_data:\n",
       "        return f\"The weather in {location} is {weather_data[location_lower]}\"\n",
       "    else:\n",
       "        return f\"The weather in {location} is sunny with 20Â°C (mock data)\"\n",
       "\n",
       "def search_web(query: str) -> str:\n",
       "    \"\"\"Search the web for information.\"\"\"\n",
       "    return f\"Search results for '{query}': Here are some relevant articles and information about {query}. This is mock data - in a real implementation, this would connect to a search API.\"\n",
       "\n",
       "def calculate_math(expression: str) -> str:\n",
       "    \"\"\"Calculate mathematical expressions safely.\"\"\"\n",
       "    try:\n",
       "        allowed_chars = set('0123456789+-*/().,= ')\n",
       "        if all(c in allowed_chars for c in expression):\n",
       "            result = eval(expression)\n",
       "            return f\"The result of {expression} is {result}\"\n",
       "        else:\n",
       "            return \"Invalid mathematical expression. Only basic arithmetic operations are allowed.\"\n",
       "    except Exception as e:\n",
       "        return f\"Error calculating {expression}: {str(e)}\"\n",
       "\n",
       "tools = [get_weather, search_web, calculate_math]\n",
       "llm_with_tools = llm.bind_tools(tools)\n",
       "\n",
       "def agent_node(state: AgentState):\n",
       "    \"\"\"The main agent reasoning node.\"\"\"\n",
       "    messages = state[\"messages\"]\n",
       "    \n",
       "    if not any(isinstance(msg, SystemMessage) for msg in messages):\n",
       "        system_msg = SystemMessage(content=\"\"\"You are a helpful AI assistant with access to several tools:\n",
       "\n",
       "1. get_weather(location): Get weather information for any location\n",
       "2. search_web(query): Search the web for information \n",
       "3. calculate_math(expression): Perform mathematical calculations\n",
       "\n",
       "Use these tools when appropriate to help answer user questions. Always be helpful and provide detailed, accurate responses.\"\"\")\n",
       "        messages = [system_msg] + list(messages)\n",
       "    \n",
       "    response = llm_with_tools.invoke(messages)\n",
       "    return {\"messages\": [response]}\n",
       "\n",
       "def tool_node(state: AgentState):\n",
       "    \"\"\"Execute tools when the agent calls them.\"\"\"\n",
       "    messages = state[\"messages\"]\n",
       "    last_message = messages[-1]\n",
       "    \n",
       "    tool_results = []\n",
       "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
       "        for tool_call in last_message.tool_calls:\n",
       "            tool_name = tool_call[\"name\"]\n",
       "            tool_args = tool_call[\"args\"]\n",
       "            \n",
       "            if tool_name == \"get_weather\":\n",
       "                result = get_weather(**tool_args)\n",
       "            elif tool_name == \"search_web\":\n",
       "                result = search_web(**tool_args)\n",
       "            elif tool_name == \"calculate_math\":\n",
       "                result = calculate_math(**tool_args)\n",
       "            else:\n",
       "                result = f\"Unknown tool: {tool_name}\"\n",
       "            \n",
       "            tool_message = ToolMessage(\n",
       "                content=result,\n",
       "                tool_call_id=tool_call[\"id\"]\n",
       "            )\n",
       "            tool_results.append(tool_message)\n",
       "    \n",
       "    return {\"messages\": tool_results}\n",
       "\n",
       "def should_continue(state: AgentState) -> Literal[\"tools\", \"end\"]:\n",
       "    \"\"\"Determine if we should continue to tools or end.\"\"\"\n",
       "    messages = state[\"messages\"]\n",
       "    last_message = messages[-1]\n",
       "    \n",
       "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
       "        return \"tools\"\n",
       "    else:\n",
       "        return \"end\"\n",
       "\n",
       "# Build the graph\n",
       "workflow = StateGraph(AgentState)\n",
       "workflow.add_node(\"agent\", agent_node)\n",
       "workflow.add_node(\"tools\", tool_node)\n",
       "workflow.add_edge(START, \"agent\")\n",
       "workflow.add_conditional_edges(\n",
       "    \"agent\",\n",
       "    should_continue,\n",
       "    {\n",
       "        \"tools\": \"tools\",\n",
       "        \"end\": END\n",
       "    }\n",
       ")\n",
       "workflow.add_edge(\"tools\", \"agent\")\n",
       "\n",
       "# Compile the graph\n",
       "graph = workflow.compile()\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def show_py_file(filepath):\n",
    "    \"\"\"Display Python file contents as markdown code block\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Create markdown with python syntax highlighting\n",
    "        markdown_content = f\"```python\\n{content}\\n```\"\n",
    "        display(Markdown(markdown_content))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "\n",
    "# Usage\n",
    "show_py_file('./agents/example1/Example1Agent.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f79d8",
   "metadata": {},
   "source": [
    "Test the Agent Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6bc3463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Running test queries...\n",
      "\n",
      "============================================================\n",
      "ðŸ¤– Testing query: What's the weather like in London?\n",
      "============================================================\n",
      "\n",
      "ðŸ“‹ Conversation History:\n",
      "1. HumanMessage: What's the weather like in London?\n",
      "2. AIMessage: [Called tools: ['get_weather']]\n",
      "3. ToolMessage: The weather in London is Cloudy with light rain, 15Â°C\n",
      "4. AIMessage: The weather in London is currently cloudy with light rain, and the temperature is around 15Â°C.\n",
      "\n",
      "============================================================\n",
      "ðŸ¤– Testing query: Calculate 25 * 14 + 100\n",
      "============================================================\n",
      "\n",
      "ðŸ“‹ Conversation History:\n",
      "1. HumanMessage: Calculate 25 * 14 + 100\n",
      "2. AIMessage: [Called tools: ['calculate_math']]\n",
      "3. ToolMessage: The result of 25 * 14 + 100 is 450\n",
      "4. AIMessage: The result of the calculation \\( 25 \\times 14 + 100 \\) is 450.\n",
      "\n",
      "============================================================\n",
      "ðŸ¤– Testing query: Search for information about LangGraph\n",
      "============================================================\n",
      "\n",
      "ðŸ“‹ Conversation History:\n",
      "1. HumanMessage: Search for information about LangGraph\n",
      "2. AIMessage: [Called tools: ['search_web']]\n",
      "3. ToolMessage: Search results for 'LangGraph': Here are some relevant articles and information about LangGraph. Thi...\n",
      "4. AIMessage: I found some information about LangGraph. However, the details are not specific since this is mock d...\n",
      "\n",
      "============================================================\n",
      "ðŸ¤– Testing query: What's 15% of 240?\n",
      "============================================================\n",
      "\n",
      "ðŸ“‹ Conversation History:\n",
      "1. HumanMessage: What's 15% of 240?\n",
      "2. AIMessage: [Called tools: ['calculate_math']]\n",
      "3. ToolMessage: The result of 0.15 * 240 is 36.0\n",
      "4. AIMessage: 15% of 240 is 36.0.\n"
     ]
    }
   ],
   "source": [
    "def test_agent_interaction(query: str):\n",
    "    \"\"\"Test a single interaction with the agent.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸ¤– Testing query: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    result = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=query)]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nðŸ“‹ Conversation History:\")\n",
    "    for i, message in enumerate(result[\"messages\"]):\n",
    "        message_type = type(message).__name__\n",
    "        if hasattr(message, 'tool_calls') and message.tool_calls:\n",
    "            print(f\"{i+1}. {message_type}: [Called tools: {[tc['name'] for tc in message.tool_calls]}]\")\n",
    "        else:\n",
    "            content = message.content[:100] + \"...\" if len(message.content) > 100 else message.content\n",
    "            print(f\"{i+1}. {message_type}: {content}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test different types of queries\n",
    "test_queries = [\n",
    "    \"What's the weather like in London?\",\n",
    "    \"Calculate 25 * 14 + 100\",\n",
    "    \"Search for information about LangGraph\",\n",
    "    \"What's 15% of 240?\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ§ª Running test queries...\")\n",
    "for query in test_queries:\n",
    "    test_agent_interaction(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b10b55",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "000b9e96",
   "metadata": {},
   "source": [
    "Test different types of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89956709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
